{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b9c57fa-80b7-464a-8992-53432ae74311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (4.37.2)\n",
      "Collecting gradio\n",
      "  Downloading gradio-4.39.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (22.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (4.2.0)\n",
      "Requirement already satisfied: fastapi in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (0.103.0)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (0.3.0)\n",
      "Collecting gradio-client==1.1.1 (from gradio)\n",
      "  Downloading gradio_client-1.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (0.26.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (0.23.1)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (6.4.0)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (3.1.3)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (3.8.4)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (3.9.15)\n",
      "Requirement already satisfied: packaging in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (23.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (10.2.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (2.5.3)\n",
      "Requirement already satisfied: pydub in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (0.0.9)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (0.3.5)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (2.8.5)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (0.12.3)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (4.11.0)\n",
      "Requirement already satisfied: urllib3~=2.0 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (2.2.1)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (0.20.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio-client==1.1.1->gradio) (2024.3.1)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio-client==1.1.1->gradio) (10.4)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
      "Requirement already satisfied: requests in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (4.66.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from pydantic>=2.0->gradio) (2.14.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (12.5.1)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from fastapi->gradio) (0.27.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.17.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
      "Downloading gradio-4.39.0-py3-none-any.whl (12.4 MB)\n",
      "   ---------------------------------------- 0.0/12.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/12.4 MB 1.3 MB/s eta 0:00:10\n",
      "    --------------------------------------- 0.2/12.4 MB 1.7 MB/s eta 0:00:08\n",
      "    --------------------------------------- 0.2/12.4 MB 1.5 MB/s eta 0:00:09\n",
      "    --------------------------------------- 0.3/12.4 MB 1.5 MB/s eta 0:00:09\n",
      "    --------------------------------------- 0.3/12.4 MB 1.5 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.4/12.4 MB 1.5 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.4/12.4 MB 1.4 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.5/12.4 MB 1.3 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.5/12.4 MB 1.2 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.6/12.4 MB 1.2 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.7/12.4 MB 1.2 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.7/12.4 MB 1.3 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.7/12.4 MB 1.2 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.8/12.4 MB 1.2 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.9/12.4 MB 1.2 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 0.9/12.4 MB 1.2 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 1.0/12.4 MB 1.3 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 1.1/12.4 MB 1.2 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 1.2/12.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.3/12.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.4/12.4 MB 1.4 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 1.6/12.4 MB 1.4 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 1.6/12.4 MB 1.5 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 1.7/12.4 MB 1.5 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.9/12.4 MB 1.6 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 1.9/12.4 MB 1.5 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 2.0/12.4 MB 1.5 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 2.1/12.4 MB 1.6 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 2.2/12.4 MB 1.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 2.2/12.4 MB 1.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 2.4/12.4 MB 1.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 2.4/12.4 MB 1.6 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 2.5/12.4 MB 1.6 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 2.7/12.4 MB 1.6 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 2.7/12.4 MB 1.6 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 2.8/12.4 MB 1.6 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 2.9/12.4 MB 1.6 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 3.0/12.4 MB 1.6 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 3.0/12.4 MB 1.6 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 3.1/12.4 MB 1.6 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 3.1/12.4 MB 1.6 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 3.3/12.4 MB 1.7 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 3.5/12.4 MB 1.7 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 3.6/12.4 MB 1.7 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 3.9/12.4 MB 1.8 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 4.0/12.4 MB 1.8 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 4.1/12.4 MB 1.8 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 4.4/12.4 MB 1.9 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 4.5/12.4 MB 1.9 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.8/12.4 MB 2.0 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 4.9/12.4 MB 2.0 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 5.0/12.4 MB 2.0 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 5.2/12.4 MB 2.0 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 5.2/12.4 MB 2.0 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 5.3/12.4 MB 2.0 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 5.4/12.4 MB 2.0 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 5.5/12.4 MB 2.0 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 5.5/12.4 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 5.7/12.4 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 5.8/12.4 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 6.0/12.4 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 6.0/12.4 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 6.2/12.4 MB 2.0 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 6.3/12.4 MB 2.0 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 6.5/12.4 MB 2.1 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 6.5/12.4 MB 2.1 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 6.7/12.4 MB 2.1 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 6.9/12.4 MB 2.1 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 7.0/12.4 MB 2.1 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 7.0/12.4 MB 2.1 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 7.2/12.4 MB 2.1 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 7.4/12.4 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 7.6/12.4 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 7.7/12.4 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 7.8/12.4 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 8.0/12.4 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 8.0/12.4 MB 2.2 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 8.2/12.4 MB 2.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.4/12.4 MB 2.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.7/12.4 MB 2.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.7/12.4 MB 2.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.9/12.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 9.1/12.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 9.3/12.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 9.4/12.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 9.6/12.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 9.8/12.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 9.8/12.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 9.9/12.4 MB 2.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 10.0/12.4 MB 2.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 10.1/12.4 MB 2.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.3/12.4 MB 2.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.4/12.4 MB 2.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.4/12.4 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.7/12.4 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.9/12.4 MB 2.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.2/12.4 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.3/12.4 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.4/12.4 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.5/12.4 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.7/12.4 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.9/12.4 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.1/12.4 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.4/12.4 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.4/12.4 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.4/12.4 MB 2.8 MB/s eta 0:00:00\n",
      "Downloading gradio_client-1.1.1-py3-none-any.whl (318 kB)\n",
      "   ---------------------------------------- 0.0/318.2 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 92.2/318.2 kB 5.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 256.0/318.2 kB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 318.2/318.2 kB 3.9 MB/s eta 0:00:00\n",
      "Installing collected packages: gradio-client, gradio\n",
      "  Attempting uninstall: gradio-client\n",
      "    Found existing installation: gradio_client 1.0.2\n",
      "    Uninstalling gradio_client-1.0.2:\n",
      "      Successfully uninstalled gradio_client-1.0.2\n",
      "  Attempting uninstall: gradio\n",
      "    Found existing installation: gradio 4.37.2\n",
      "    Uninstalling gradio-4.37.2:\n",
      "      Successfully uninstalled gradio-4.37.2\n",
      "Successfully installed gradio-4.39.0 gradio-client-1.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17400bed-5fe8-4f82-9bdc-4f9b5fec1c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: click in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from nltk) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\gefhz\\anaconda3\\envs\\dev\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4 nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a50fc315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "468a2daa-001f-4cb6-8ab7-6b21563b2a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment set up complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gefhz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gefhz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "#Import libraries and setup environment\n",
    "import requests\n",
    "import gradio as gr\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import urllib.parse\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# API keys (store these securely, preferably as environment variables)\n",
    "NEWSAPI_KEY = os.getenv(\"NEWSAPI_KEY\")\n",
    "MEDIASTACK_KEY = os.getenv(\"MEDIASTACK_KEY\")\n",
    "\n",
    "print(\"Environment set up complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbbf8517-52e1-4c87-bc78-1a4c200739be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Caching functions\n",
    "def cache_news(topic, language, articles):\n",
    "    cache_dir = \"news_cache\"\n",
    "    if not os.path.exists(cache_dir):\n",
    "        os.makedirs(cache_dir)\n",
    "    cache_file = os.path.join(cache_dir, f\"cache_{topic}_{language}.json\")\n",
    "    with open(cache_file, 'w') as f:\n",
    "        json.dump({'timestamp': datetime.now().isoformat(), 'articles': articles}, f)\n",
    "    print(f\"Cached {len(articles)} articles for topic '{topic}' in language '{language}'\")\n",
    "\n",
    "def get_cached_news(topic, language):\n",
    "    cache_dir = \"news_cache\"\n",
    "    cache_file = os.path.join(cache_dir, f\"cache_{topic}_{language}.json\")\n",
    "    try:\n",
    "        with open(cache_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            if datetime.fromisoformat(data['timestamp']) > datetime.now() - timedelta(hours=1):\n",
    "                print(f\"Retrieved {len(data['articles'])} cached articles for topic '{topic}' in language '{language}'\")\n",
    "                return data['articles']\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No cache found for topic '{topic}' in language '{language}'\")\n",
    "    return None\n",
    "\n",
    "print(\"Caching functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5887452-53db-4af7-9701-902ab84dc86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News fetching function defined.\n"
     ]
    }
   ],
   "source": [
    "# News fetching function\n",
    "def fetch_news(api, query, from_date, to_date, language='en', sort='published_desc', limit=10):\n",
    "    if api == \"newsapi\":\n",
    "        sort_param = {\n",
    "            \"published_desc\": \"publishedAt\",\n",
    "            \"published_asc\": \"publishedAt\",\n",
    "            \"popularity\": \"popularity\"\n",
    "        }.get(sort, \"publishedAt\")\n",
    "        url = f\"http://newsapi.org/v2/everything?q={urllib.parse.quote(query)}&from={from_date}&to={to_date}&sortBy={sort_param}&pageSize={limit}&language={language}&apiKey={NEWSAPI_KEY}\"\n",
    "    elif api == \"mediastack\":\n",
    "        mediastack_sort = \"published_desc\" if sort in [\"published_desc\", \"popularity\"] else \"published_asc\"\n",
    "        url = f\"http://api.mediastack.com/v1/news?access_key={MEDIASTACK_KEY}&keywords={urllib.parse.quote(query)}&date={from_date},{to_date}&sort={mediastack_sort}&limit={limit}&languages={language}\"\n",
    "    \n",
    "    print(f\"Fetching news from {api}...\")\n",
    "    print(f\"URL: {url}\")\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    print(f\"Response status code: {response.status_code}\")\n",
    "    print(f\"Response data: {data}\")\n",
    "    \n",
    "    if api == \"newsapi\" and sort == \"published_asc\":\n",
    "        data['articles'] = data['articles'][::-1]\n",
    "    elif api == \"mediastack\" and sort == \"popularity\":\n",
    "        data['data'] = sorted(data['data'], key=lambda x: x.get('published_at', ''), reverse=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "print(\"News fetching function defined.\")\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "267e2920-2901-4d06-8036-0293c7cb9837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text preprocessing and summarization functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Text preprocessing and summarization functions\n",
    "def preprocess_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text, flags=re.MULTILINE)\n",
    "    # Remove HTML tags\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "def summarize_text(text, num_sentences=3):\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and tokenize\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text.lower())\n",
    "    words = [word for word in words if word.isalnum() and word not in stop_words]\n",
    "    \n",
    "    # Calculate word frequencies\n",
    "    freq = FreqDist(words)\n",
    "    \n",
    "    # Calculate sentence scores based on word frequencies\n",
    "    sentence_scores = {}\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for word in word_tokenize(sentence.lower()):\n",
    "            if word in freq:\n",
    "                if i in sentence_scores:\n",
    "                    sentence_scores[i] += freq[word]\n",
    "                else:\n",
    "                    sentence_scores[i] = freq[word]\n",
    "    \n",
    "    # Get the top N sentences with highest scores\n",
    "    top_sentences = sorted(sentence_scores, key=sentence_scores.get, reverse=True)[:num_sentences]\n",
    "    \n",
    "    # Combine the top sentences in their original order\n",
    "    summary = ' '.join([sentences[i] for i in sorted(top_sentences)])\n",
    "    \n",
    "    return summary\n",
    "\n",
    "def get_top_snippets(articles, n=3):\n",
    "    def get_article_date(article):\n",
    "        return article.get('publishedAt') or article.get('published_at') or ''\n",
    "    \n",
    "    sorted_articles = sorted(articles, key=get_article_date, reverse=True)\n",
    "    snippets = []\n",
    "    for article in sorted_articles[:n]:\n",
    "        title = article.get('title', 'No title')\n",
    "        description = article.get('description', 'No description')\n",
    "        snippet = f\"{title}: {description[:100]}...\"\n",
    "        snippets.append(snippet)\n",
    "    return snippets\n",
    "\n",
    "print(\"Text preprocessing and summarization functions defined.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f0ec85f-4b15-4b33-98ab-0187806dcbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main news summary function defined.\n"
     ]
    }
   ],
   "source": [
    "#Main news summary\n",
    "def get_news_summary(topic, language='en', sort='published_desc', limit=10):\n",
    "    try:\n",
    "        cached_articles = get_cached_news(topic, language)\n",
    "        if cached_articles:\n",
    "            articles = cached_articles\n",
    "            print(f\"Using cached articles. Number of articles: {len(articles)}\")\n",
    "        else:\n",
    "            today = datetime.now().date()\n",
    "            yesterday = today - timedelta(days=1)\n",
    "            \n",
    "            # Fetch news from both APIs\n",
    "            newsapi_data = fetch_news(\"newsapi\", topic, yesterday, today, language, sort, limit)\n",
    "            mediastack_data = fetch_news(\"mediastack\", topic, yesterday.strftime(\"%Y-%m-%d\"), today.strftime(\"%Y-%m-%d\"), language, sort, limit)\n",
    "            \n",
    "            # Combine articles from both sources\n",
    "            articles = newsapi_data.get('articles', []) + mediastack_data.get('data', [])\n",
    "            print(f\"Fetched articles. NewsAPI: {len(newsapi_data.get('articles', []))}, MediaStack: {len(mediastack_data.get('data', []))}\")\n",
    "            \n",
    "            if articles:\n",
    "                cache_news(topic, language, articles)\n",
    "        \n",
    "        if not articles:\n",
    "            return f\"No articles found for the topic '{topic}'. Please try a different topic or check your API keys.\"\n",
    "        \n",
    "        print(f\"Total number of articles: {len(articles)}\")\n",
    "        \n",
    "        # Combine the content of all articles and preprocess\n",
    "        all_content = \" \".join([article.get('content', '') or article.get('description', '') for article in articles])\n",
    "        preprocessed_content = preprocess_text(all_content)\n",
    "        \n",
    "        # Generate summary\n",
    "        summary = summarize_text(preprocessed_content, num_sentences=3)\n",
    "        \n",
    "        # Get top snippets\n",
    "        top_snippets = get_top_snippets(articles)\n",
    "        \n",
    "        # Prepare sources\n",
    "        sources = set()\n",
    "        for article in articles:\n",
    "            if isinstance(article, dict):\n",
    "                source = article.get('source', {})\n",
    "                if isinstance(source, dict):\n",
    "                    sources.add(source.get('name') or 'Unknown')\n",
    "                else:\n",
    "                    sources.add(source or 'Unknown')\n",
    "            else:\n",
    "                sources.add('Unknown')\n",
    "        sources_str = \", \".join(sources)\n",
    "        \n",
    "        # Prepare the output\n",
    "        output = f\"Summary of recent news on '{topic}':\\n\\n{summary}\\n\\nTop Articles:\\n\"\n",
    "        for i, snippet in enumerate(top_snippets, 1):\n",
    "            output += f\"{i}. {snippet}\\n\"\n",
    "        output += f\"\\nSources: {sources_str}\"\n",
    "        \n",
    "        return output\n",
    "    except Exception as e:\n",
    "        error_msg = f\"An error occurred: {str(e)}\\n\\nTraceback:\\n{traceback.format_exc()}\"\n",
    "        print(error_msg)\n",
    "        return f\"An error occurred while processing your request. Please try again later.\\nError details: {str(e)}\"\n",
    "\n",
    "print(\"Main news summary function defined.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "451c58bd-6d4b-4eff-ab9a-2904e25e9578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradio interface defined.\n"
     ]
    }
   ],
   "source": [
    "#Gradio Interface\n",
    "iface = gr.Interface(\n",
    "    fn=get_news_summary,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Enter the topic you want a summary for:\"),\n",
    "        gr.Dropdown(choices=[\"en\", \"de\", \"es\", \"fr\", \"it\", \"nl\", \"no\", \"pt\", \"ru\", \"se\", \"zh\"], label=\"Language\", value=\"en\"),\n",
    "        gr.Dropdown(choices=[\"published_desc\", \"published_asc\", \"popularity\"], label=\"Sort By\", value=\"published_desc\"),\n",
    "        gr.Slider(minimum=1, maximum=25, step=1, label=\"Number of Articles\", value=10)\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Summary and Sources\"),\n",
    "    title=\"News Summarizer\",\n",
    "    description=\"Get a summary of the latest news on a given topic from multiple sources.\"\n",
    ")\n",
    "\n",
    "print(\"Gradio interface defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea87b98d-a602-4b1c-809a-ad502ef9ddf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cache found for topic 'russia' in language 'en'\n",
      "Fetching news from newsapi...\n",
      "URL: http://newsapi.org/v2/everything?q=russia&from=2024-07-22&to=2024-07-23&sortBy=publishedAt&pageSize=18&language=en&apiKey=None\n",
      "Response status code: 401\n",
      "Response data: {'status': 'error', 'code': 'apiKeyInvalid', 'message': 'Your API key is invalid or incorrect. Check your key, or go to https://newsapi.org to create a free API key.'}\n",
      "Fetching news from mediastack...\n",
      "URL: http://api.mediastack.com/v1/news?access_key=None&keywords=russia&date=2024-07-22,2024-07-23&sort=published_desc&limit=18&languages=en\n",
      "Response status code: 401\n",
      "Response data: {'error': {'code': 'invalid_access_key', 'message': 'You have not supplied a valid API Access Key.'}}\n",
      "Fetched articles. NewsAPI: 0, MediaStack: 0\n",
      "No cache found for topic 'putin' in language 'en'\n",
      "Fetching news from newsapi...\n",
      "URL: http://newsapi.org/v2/everything?q=putin&from=2024-07-22&to=2024-07-23&sortBy=publishedAt&pageSize=18&language=en&apiKey=None\n",
      "Response status code: 401\n",
      "Response data: {'status': 'error', 'code': 'apiKeyInvalid', 'message': 'Your API key is invalid or incorrect. Check your key, or go to https://newsapi.org to create a free API key.'}\n",
      "Fetching news from mediastack...\n",
      "URL: http://api.mediastack.com/v1/news?access_key=None&keywords=putin&date=2024-07-22,2024-07-23&sort=published_desc&limit=18&languages=en\n",
      "Response status code: 401\n",
      "Response data: {'error': {'code': 'invalid_access_key', 'message': 'You have not supplied a valid API Access Key.'}}\n",
      "Fetched articles. NewsAPI: 0, MediaStack: 0\n",
      "No cache found for topic 'california fires' in language 'en'\n",
      "Fetching news from newsapi...\n",
      "URL: http://newsapi.org/v2/everything?q=california%20fires&from=2024-07-22&to=2024-07-23&sortBy=publishedAt&pageSize=18&language=en&apiKey=None\n",
      "Response status code: 401\n",
      "Response data: {'status': 'error', 'code': 'apiKeyInvalid', 'message': 'Your API key is invalid or incorrect. Check your key, or go to https://newsapi.org to create a free API key.'}\n",
      "Fetching news from mediastack...\n",
      "URL: http://api.mediastack.com/v1/news?access_key=None&keywords=california%20fires&date=2024-07-22,2024-07-23&sort=published_desc&limit=18&languages=en\n",
      "Response status code: 401\n",
      "Response data: {'error': {'code': 'invalid_access_key', 'message': 'You have not supplied a valid API Access Key.'}}\n",
      "Fetched articles. NewsAPI: 0, MediaStack: 0\n"
     ]
    }
   ],
   "source": [
    "#Launch the Interface\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae5e3fc-9c95-4b01-b512-6979a686ddbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85966e0-d486-4aa2-b928-3329e7d2a03f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241f0897-3fe2-4a01-a1a5-bfd18c371f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed04a470-cf44-40bc-9a05-4687168464b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f3bf5d-97eb-49bb-8f2a-2f5411c72a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
