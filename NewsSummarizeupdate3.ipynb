{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b9c57fa-80b7-464a-8992-53432ae74311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in c:\\users\\19727\\anaconda3\\lib\\site-packages (4.39.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio) (4.2.0)\n",
      "Requirement already satisfied: fastapi in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio) (0.111.0)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio) (0.3.2)\n",
      "Requirement already satisfied: gradio-client==1.1.1 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio) (1.1.1)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio) (0.20.3)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio) (6.4.0)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio) (3.1.3)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio) (3.8.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio) (3.10.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio) (2.1.4)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio) (10.2.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio) (2.8.2)\n",
      "Requirement already satisfied: pydub in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio) (0.0.9)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio) (0.5.1)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio) (0.12.3)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: urllib3~=2.0 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio) (2.0.7)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio) (0.30.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio-client==1.1.1->gradio) (2023.10.0)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from gradio-client==1.1.1->gradio) (11.0.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\19727\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\19727\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\19727\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
      "Requirement already satisfied: requests in c:\\users\\19727\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (4.65.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.3.5)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from fastapi->gradio) (0.37.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from fastapi->gradio) (0.0.4)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from fastapi->gradio) (5.4.0)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from fastapi->gradio) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\19727\\anaconda3\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from email_validator>=2.0.0->fastapi->gradio) (2.6.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio) (1.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio) (0.22.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17400bed-5fe8-4f82-9bdc-4f9b5fec1c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\19727\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\19727\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: click in c:\\users\\19727\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\19727\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\19727\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\19727\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\19727\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4 nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a50fc315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "468a2daa-001f-4cb6-8ab7-6b21563b2a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment set up complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\19727\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\19727\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Import libraries and setup environment\n",
    "import requests\n",
    "import gradio as gr\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import urllib.parse\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# API keys (store these securely, preferably as environment variables)\n",
    "NEWSAPI_KEY = os.getenv(\"NEWSAPI_KEY\")\n",
    "MEDIASTACK_KEY = os.getenv(\"MEDIASTACK_KEY\")\n",
    "\n",
    "print(\"Environment set up complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbbf8517-52e1-4c87-bc78-1a4c200739be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Caching functions\n",
    "def cache_news(topic, language, articles):\n",
    "    cache_dir = \"news_cache\"\n",
    "    if not os.path.exists(cache_dir):\n",
    "        os.makedirs(cache_dir)\n",
    "    cache_file = os.path.join(cache_dir, f\"cache_{topic}_{language}.json\")\n",
    "    with open(cache_file, 'w') as f:\n",
    "        json.dump({'timestamp': datetime.now().isoformat(), 'articles': articles}, f)\n",
    "    print(f\"Cached {len(articles)} articles for topic '{topic}' in language '{language}'\")\n",
    "\n",
    "def get_cached_news(topic, language):\n",
    "    cache_dir = \"news_cache\"\n",
    "    cache_file = os.path.join(cache_dir, f\"cache_{topic}_{language}.json\")\n",
    "    try:\n",
    "        with open(cache_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            if datetime.fromisoformat(data['timestamp']) > datetime.now() - timedelta(hours=1):\n",
    "                print(f\"Retrieved {len(data['articles'])} cached articles for topic '{topic}' in language '{language}'\")\n",
    "                return data['articles']\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No cache found for topic '{topic}' in language '{language}'\")\n",
    "    return None\n",
    "\n",
    "print(\"Caching functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5887452-53db-4af7-9701-902ab84dc86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News fetching function defined.\n"
     ]
    }
   ],
   "source": [
    "# News fetching function\n",
    "def fetch_news(api, query, from_date, to_date, language='en', sort='published_desc', limit=10):\n",
    "    if api == \"newsapi\":\n",
    "        sort_param = {\n",
    "            \"published_desc\": \"publishedAt\",\n",
    "            \"published_asc\": \"publishedAt\",\n",
    "            \"popularity\": \"popularity\"\n",
    "        }.get(sort, \"publishedAt\")\n",
    "        url = f\"http://newsapi.org/v2/everything?q={urllib.parse.quote(query)}&from={from_date}&to={to_date}&sortBy={sort_param}&pageSize={limit}&language={language}&apiKey={NEWSAPI_KEY}\"\n",
    "    elif api == \"mediastack\":\n",
    "        mediastack_sort = \"published_desc\" if sort in [\"published_desc\", \"popularity\"] else \"published_asc\"\n",
    "        url = f\"http://api.mediastack.com/v1/news?access_key={MEDIASTACK_KEY}&keywords={urllib.parse.quote(query)}&date={from_date},{to_date}&sort={mediastack_sort}&limit={limit}&languages={language}\"\n",
    "    \n",
    "    print(f\"Fetching news from {api}...\")\n",
    "    print(f\"URL: {url}\")\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    print(f\"Response status code: {response.status_code}\")\n",
    "    print(f\"Response data: {data}\")\n",
    "    \n",
    "    if api == \"newsapi\" and sort == \"published_asc\":\n",
    "        data['articles'] = data['articles'][::-1]\n",
    "    elif api == \"mediastack\" and sort == \"popularity\":\n",
    "        data['data'] = sorted(data['data'], key=lambda x: x.get('published_at', ''), reverse=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "print(\"News fetching function defined.\")\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "267e2920-2901-4d06-8036-0293c7cb9837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text preprocessing and summarization functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Text preprocessing and summarization functions\n",
    "def preprocess_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text, flags=re.MULTILINE)\n",
    "    # Remove HTML tags\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "def summarize_text(text, num_sentences=3):\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and tokenize\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text.lower())\n",
    "    words = [word for word in words if word.isalnum() and word not in stop_words]\n",
    "    \n",
    "    # Calculate word frequencies\n",
    "    freq = FreqDist(words)\n",
    "    \n",
    "    # Calculate sentence scores based on word frequencies\n",
    "    sentence_scores = {}\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for word in word_tokenize(sentence.lower()):\n",
    "            if word in freq:\n",
    "                if i in sentence_scores:\n",
    "                    sentence_scores[i] += freq[word]\n",
    "                else:\n",
    "                    sentence_scores[i] = freq[word]\n",
    "    \n",
    "    # Get the top N sentences with highest scores\n",
    "    top_sentences = sorted(sentence_scores, key=sentence_scores.get, reverse=True)[:num_sentences]\n",
    "    \n",
    "    # Combine the top sentences in their original order\n",
    "    summary = ' '.join([sentences[i] for i in sorted(top_sentences)])\n",
    "    \n",
    "    return summary\n",
    "\n",
    "def get_top_snippets(articles, n=3):\n",
    "    def get_article_date(article):\n",
    "        return article.get('publishedAt') or article.get('published_at') or ''\n",
    "    \n",
    "    sorted_articles = sorted(articles, key=get_article_date, reverse=True)\n",
    "    snippets = []\n",
    "    for article in sorted_articles[:n]:\n",
    "        title = article.get('title', 'No title')\n",
    "        description = article.get('description', 'No description')\n",
    "        snippet = f\"{title}: {description[:100]}...\"\n",
    "        snippets.append(snippet)\n",
    "    return snippets\n",
    "\n",
    "print(\"Text preprocessing and summarization functions defined.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f0ec85f-4b15-4b33-98ab-0187806dcbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main news summary function defined.\n"
     ]
    }
   ],
   "source": [
    "#Main news summary\n",
    "def get_news_summary(topic, language='en', sort='published_desc', limit=10):\n",
    "    try:\n",
    "        cached_articles = get_cached_news(topic, language)\n",
    "        if cached_articles:\n",
    "            articles = cached_articles\n",
    "            print(f\"Using cached articles. Number of articles: {len(articles)}\")\n",
    "        else:\n",
    "            today = datetime.now().date()\n",
    "            yesterday = today - timedelta(days=1)\n",
    "            \n",
    "            # Fetch news from both APIs\n",
    "            newsapi_data = fetch_news(\"newsapi\", topic, yesterday, today, language, sort, limit)\n",
    "            mediastack_data = fetch_news(\"mediastack\", topic, yesterday.strftime(\"%Y-%m-%d\"), today.strftime(\"%Y-%m-%d\"), language, sort, limit)\n",
    "            \n",
    "            # Combine articles from both sources\n",
    "            articles = newsapi_data.get('articles', []) + mediastack_data.get('data', [])\n",
    "            print(f\"Fetched articles. NewsAPI: {len(newsapi_data.get('articles', []))}, MediaStack: {len(mediastack_data.get('data', []))}\")\n",
    "            \n",
    "            if articles:\n",
    "                cache_news(topic, language, articles)\n",
    "        \n",
    "        if not articles:\n",
    "            return f\"No articles found for the topic '{topic}'. Please try a different topic or check your API keys.\"\n",
    "        \n",
    "        print(f\"Total number of articles: {len(articles)}\")\n",
    "        \n",
    "        # Combine the content of all articles and preprocess\n",
    "        all_content = \" \".join([article.get('content', '') or article.get('description', '') for article in articles])\n",
    "        preprocessed_content = preprocess_text(all_content)\n",
    "        \n",
    "        # Generate summary\n",
    "        summary = summarize_text(preprocessed_content, num_sentences=3)\n",
    "        \n",
    "        # Get top snippets\n",
    "        top_snippets = get_top_snippets(articles)\n",
    "        \n",
    "        # Prepare sources\n",
    "        sources = set()\n",
    "        for article in articles:\n",
    "            if isinstance(article, dict):\n",
    "                source = article.get('source', {})\n",
    "                if isinstance(source, dict):\n",
    "                    sources.add(source.get('name') or 'Unknown')\n",
    "                else:\n",
    "                    sources.add(source or 'Unknown')\n",
    "            else:\n",
    "                sources.add('Unknown')\n",
    "        sources_str = \", \".join(sources)\n",
    "        \n",
    "        # Prepare the output\n",
    "        output = f\"Summary of recent news on '{topic}':\\n\\n{summary}\\n\\nTop Articles:\\n\"\n",
    "        for i, snippet in enumerate(top_snippets, 1):\n",
    "            output += f\"{i}. {snippet}\\n\"\n",
    "        output += f\"\\nSources: {sources_str}\"\n",
    "        \n",
    "        return output\n",
    "    except Exception as e:\n",
    "        error_msg = f\"An error occurred: {str(e)}\\n\\nTraceback:\\n{traceback.format_exc()}\"\n",
    "        print(error_msg)\n",
    "        return f\"An error occurred while processing your request. Please try again later.\\nError details: {str(e)}\"\n",
    "\n",
    "print(\"Main news summary function defined.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "451c58bd-6d4b-4eff-ab9a-2904e25e9578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradio interface defined.\n"
     ]
    }
   ],
   "source": [
    "#Gradio Interface\n",
    "iface = gr.Interface(\n",
    "    fn=get_news_summary,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Enter the topic you want a summary for:\"),\n",
    "        gr.Dropdown(choices=[\"en\", \"de\", \"es\", \"fr\", \"it\", \"nl\", \"no\", \"pt\", \"ru\", \"se\", \"zh\"], label=\"Language\", value=\"en\"),\n",
    "        gr.Dropdown(choices=[\"published_desc\", \"published_asc\", \"popularity\"], label=\"Sort By\", value=\"published_desc\"),\n",
    "        gr.Slider(minimum=1, maximum=25, step=1, label=\"Number of Articles\", value=10)\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Summary and Sources\"),\n",
    "    title=\"News Summarizer\",\n",
    "    description=\"Get a summary of the latest news on a given topic from multiple sources.\"\n",
    ")\n",
    "\n",
    "print(\"Gradio interface defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea87b98d-a602-4b1c-809a-ad502ef9ddf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 4 cached articles for topic 'technology' in language 'en'\n",
      "Using cached articles. Number of articles: 4\n",
      "Total number of articles: 4\n"
     ]
    }
   ],
   "source": [
    "#Launch the Interface\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae5e3fc-9c95-4b01-b512-6979a686ddbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85966e0-d486-4aa2-b928-3329e7d2a03f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241f0897-3fe2-4a01-a1a5-bfd18c371f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed04a470-cf44-40bc-9a05-4687168464b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f3bf5d-97eb-49bb-8f2a-2f5411c72a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
